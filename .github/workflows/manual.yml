name: Manual scraper run

on:
  workflow_dispatch:

jobs:
  prepare:
    runs-on: ubuntu-latest
    outputs:
      stores_matrix: ${{ steps.build-matrix.outputs.stores_matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Build stores matrix
        id: build-matrix
        run: |
          node - <<'NODE'
          const fs = require("fs");

          const raw = JSON.parse(
            fs.readFileSync("data/canadian_tire_stores.json", "utf8")
          );

          const slugify = (input) => {
            return String(input || "")
              .normalize("NFD")
              .replace(/[\u0300-\u036f]/g, "")
              .toLowerCase()
              .replace(/[^a-z0-9]+/g, "-")
              .replace(/^-+|-+$/g, "")
              .replace(/-+/g, "-");
          };

          const stores = raw.slice(0, 4).map((store) => {
            const storeId = String(store.storeId ?? store.id ?? "");
            const storeName = String(store.storeName ?? store.city ?? store.name ?? "");
            const storeSlug = `${storeId}-${slugify(storeName)}`;
            return { storeId, storeName, storeSlug };
          });

          if (!stores.length) {
            throw new Error("Aucun magasin trouvÃ© dans data/canadian_tire_stores.json");
          }

          console.log("Stores matrix:");
          console.log(stores);
          const storesMatrix = JSON.stringify({ include: stores });
          fs.appendFileSync(process.env.GITHUB_OUTPUT, `stores_matrix=${storesMatrix}\n`);
          NODE

  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 240
    needs: prepare
    strategy:
      fail-fast: false
      max-parallel: 4
      matrix: ${{ fromJson(needs.prepare.outputs.stores_matrix) }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: npm

      - name: Install dependencies
        run: npm ci

      - name: Install Playwright browsers
        run: npx playwright install chromium

      - name: Run scraper for store
        run: node scraper_ct.js --storeId "${{ matrix.storeId }}" --storeName "${{ matrix.storeName }}"

      - name: Publish outputs -> public
        run: |
          set -euo pipefail
          mkdir -p public/canadiantire
          cp -R outputs/canadiantire/* public/canadiantire/

      - name: Debug outputs & public before upload
        run: |
          find outputs -maxdepth 5
          find public -maxdepth 5

      - name: Upload scraper outputs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: canadiantire-${{ matrix.storeSlug }}
          path: public/canadiantire/**
          if-no-files-found: warn

  publish-to-econoplus:
    runs-on: ubuntu-latest
    needs: scrape
    steps:
      - name: Checkout ECONOPLUS repository
        uses: actions/checkout@v4
        with:
          repository: Olivier-cousineau/econoplus
          token: ${{ secrets.ECONOPLUS }}
          ref: main
          path: econoplus

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts
          pattern: canadiantire-*

      - name: Debug artifact folders
        run: |
          set -euo pipefail
          echo "Listing artifacts tree (maxdepth 6):"
          find artifacts -maxdepth 6 -print
          if [ -z "$(find artifacts -mindepth 1 -maxdepth 6 -print -quit)" ]; then
            echo "::error::Artifacts folder is empty."
            exit 1
          fi

      - name: Sync scraper outputs into econoplus repo
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p econoplus/public/canadiantire

          echo "Artifacts tree (maxdepth 8):"
          find artifacts -maxdepth 8 -print

          mapfile -t DATA_FILES < <(find artifacts -type f -path "*/public/canadiantire/*/data.json" -print | sort)
          if [ "${#DATA_FILES[@]}" -eq 0 ]; then
            echo "No public/canadiantire data.json found. Falling back to artifacts/**/data.json"
            mapfile -t DATA_FILES < <(find artifacts -type f -name "data.json" -print | sort)
          fi

          echo "Found ${#DATA_FILES[@]} data.json file(s)"
          if [ "${#DATA_FILES[@]}" -eq 0 ]; then
            echo "::error::No data.json found in artifacts."
            exit 1
          fi

          for data_file in "${DATA_FILES[@]}"; do
            src_dir="$(dirname "$data_file")"
            slug="$(basename "$src_dir")"
            dest="econoplus/public/canadiantire/$slug"
            echo "Copy $src_dir -> $dest"
            mkdir -p "$dest"
            if command -v rsync >/dev/null 2>&1; then
              rsync -a "$src_dir"/ "$dest"/
            else
              cp -R "$src_dir"/. "$dest"/
            fi
          done

          echo "ECONOPLUS public/canadiantire sample:"
          (find econoplus/public/canadiantire -maxdepth 3 -print | head -n 100) || true

      - name: Debug ECONOPLUS git status
        working-directory: econoplus
        run: |
          echo "git status --porcelain"
          git status --porcelain

      - name: Commit & push
        working-directory: econoplus
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add public/canadiantire
          if [ -n "$(git status --porcelain)" ]; then
            git commit -m "Update Canadian Tire stores (4 stores) [skip ci]"
            git push origin HEAD:main
          else
            echo "No changes to commit."
          fi
